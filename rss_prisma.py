import feedparser
import re
import html
import random
from datetime import datetime
from collections import Counter
import numpy as np

from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity


# ---------- CONFIG PRO ----------

UMBRAL_CLUSTER = 0.63
UMBRAL_DUPLICADO = 0.87
MAX_NOTICIAS_FEED = 8

modelo = SentenceTransformer("all-MiniLM-L6-v2")


# ---------- REFERENCIAS SESGO IA ----------

referencias_politicas = {
    "progresista": modelo.encode([
        "derechos sociales igualdad feminismo pol√≠ticas p√∫blicas diversidad justicia social bienestar",
        "progresismo cambio clim√°tico pol√≠ticas sociales regulaci√≥n inclusi√≥n servicios p√∫blicos"
    ]),
    "conservador": modelo.encode([
        "seguridad fronteras defensa tradici√≥n econom√≠a mercado estabilidad control migratorio",
        "valores tradicionales seguridad nacional impuestos bajos orden liberalismo econ√≥mico"
    ])
}


# ---------- FEEDS PORTADA (Espa√±a / espa√±ol) ----------

feeds_es = {
    "El Pa√≠s": "https://feeds.elpais.com/mrss-s/pages/ep/site/elpais.com/portada",
    "El Mundo": "https://e00-elmundo.uecdn.es/elmundo/rss/portada.xml",
    "ABC": "https://www.abc.es/rss/feeds/abcPortada.xml",
    "La Vanguardia": "https://www.lavanguardia.com/rss/home.xml",
    "20 Minutos": "https://www.20minutos.es/rss/",
    "eldiario.es": "https://www.eldiario.es/rss/",
    "Europa Press": "https://www.europapress.es/rss/rss.aspx",
    "El Espa√±ol": "https://www.elespanol.com/rss/",
    "RTVE": "https://www.rtve.es/rss/",
    "BBC Mundo": "https://feeds.bbci.co.uk/mundo/rss.xml",
    "France24 Espa√±ol": "https://www.france24.com/es/rss",
    "DW Espa√±ol": "https://rss.dw.com/xml/rss-es-all",
    "El Confidencial": "https://www.elconfidencial.com/rss/",
    "P√∫blico": "https://www.publico.es/rss/",
    "HuffPost": "https://www.huffingtonpost.es/feeds/index.xml",
    "CNN Espa√±ol": "https://cnnespanol.cnn.com/feed/",
    "La Voz de Galicia": "https://www.lavozdegalicia.es/rss/portada.xml",
    "El Correo": "https://www.elcorreo.com/rss/portada.xml",
    "Diario Sur": "https://www.diariosur.es/rss/portada.xml",
    "Levante": "https://www.levante-emv.com/rss/portada.xml",
    "Heraldo": "https://www.heraldo.es/rss/portada/",
    "Xataka": "https://www.xataka.com/feedburner.xml",
    "Genbeta": "https://www.genbeta.com/feedburner.xml",
    "Trendencias": "https://www.trendencias.com/feedburner.xml",
    "Verne": "https://feeds.elpais.com/mrss-s/pages/ep/site/verne.elpais.com/portada",
    "Yorokobu": "https://www.yorokobu.es/feed/",
    "El Peri√≥dico": "https://www.elperiodico.com/es/rss/rss_portada.xml",
    "Diario Vasco": "https://www.diariovasco.com/rss/portada.xml",
    "Informaci√≥n Alicante": "https://www.informacion.es/rss/portada.xml",
    "Hipertextual": "https://hipertextual.com/feed",
    "Microsiervos": "https://www.microsiervos.com/index.xml",
    "Applesfera": "https://www.applesfera.com/feedburner.xml",
    "Expansi√≥n": "https://e00-expansion.uecdn.es/rss/portada.xml",
    "Cinco D√≠as": "https://cincodias.elpais.com/seccion/rss/portada/",
    "Nature News": "https://www.nature.com/nature.rss",
    "Scientific American": "https://rss.sciam.com/ScientificAmerican-Global",
    "Infolibre": "https://www.infolibre.es/rss",
    "El Salto": "https://www.elsaltodiario.com/rss",
    "CTXT": "https://ctxt.es/es/feed/",
    "Jacobin": "https://jacobin.com/feed"
}

feeds_internacionales = {

    # üá¨üáß Ingl√©s
    "BBC World": "https://feeds.bbci.co.uk/news/world/rss.xml",
    "CNN World": "http://rss.cnn.com/rss/edition_world.rss",
    "Reuters": "https://www.reutersagency.com/feed/?best-topics=world",
    "NYTimes": "https://rss.nytimes.com/services/xml/rss/nyt/World.xml",
    "Guardian": "https://www.theguardian.com/world/rss",
    "Bloomberg": "https://feeds.bloomberg.com/markets/news.rss",
    "Financial Times": "https://www.ft.com/world?format=rss",

    # üá´üá∑ Franc√©s
    "Le Monde": "https://www.lemonde.fr/rss/une.xml",
    "France24 FR": "https://www.france24.com/fr/rss",
    "Le Figaro": "https://www.lefigaro.fr/rss/figaro_actualites.xml",

    # üá©üá™ Alem√°n
    "Der Spiegel": "https://www.spiegel.de/international/index.rss",
    "Die Welt": "https://www.welt.de/feeds/latest.rss",

    # üáÆüáπ Italiano
    "Corriere": "https://xml2.corriereobjects.it/rss/homepage.xml",
    "La Repubblica": "https://www.repubblica.it/rss/homepage/rss2.0.xml",

    # üáµüáπ Portugu√©s
    "Publico PT": "https://www.publico.pt/rss",
    "Folha Brasil": "https://feeds.folha.uol.com.br/emcimadahora/rss091.xml",

    # üá™üá∫ Europa general
    "Politico EU": "https://www.politico.eu/feed/",
    "Euronews": "https://www.euronews.com/rss?level=theme&name=news",
     "OpenDemocracy": "https://www.opendemocracy.net/en/rss.xml",
    
    # üåè Asia
    "SCMP Hong Kong": "https://www.scmp.com/rss/91/feed",
    "Japan Times": "https://www.japantimes.co.jp/feed/",
    "China Daily": "http://www.chinadaily.com.cn/rss/world_rss.xml",

    # üåé Am√©rica Latina internacional
    "Clarin": "https://www.clarin.com/rss/lo-ultimo/",
    "El Tiempo CO": "https://www.eltiempo.com/rss/colombia.xml",
    "Granma": "http://www.granma.cu/feed",
    "Cubadebate": "http://www.cubadebate.cu/feed/",
    "Prensa Latina": "https://www.prensa-latina.cu/feed/"la
}

# ---------- LIMPIEZA ----------

stopwords = {
    "el","la","los","las","de","del","en","para","por","con",
    "sin","un","una","unos","unas","al","a","y","o","que",
    "se","su","sus","ante","como","m√°s","menos","tras"
}


def limpiar_html(texto):
    texto = html.unescape(texto)
    texto = re.sub(r'<.*?>', '', texto)
    return re.sub(r'\s+', ' ', texto).strip()


def limpiar(texto):
    texto = texto.lower()
    texto = re.sub(r'[^\w\s]', '', texto)
    palabras = texto.split()
    return [p for p in palabras if p not in stopwords and len(p) > 3]


# ---------- RECOGER NOTICIAS PORTADA ----------

noticias = []

for medio, url in feeds_es.items():
    feed = feedparser.parse(url)

    if feed.bozo:
        continue

    for entry in feed.entries[:MAX_NOTICIAS_FEED]:
        if "title" in entry and "link" in entry:
            noticias.append({
                "medio": medio,
                "titulo": limpiar_html(entry.title),
                "link": entry.link.strip()
            })


# üëâ quitar duplicados exactos por URL
noticias = list({n["link"]: n for n in noticias}.values())

print("Noticias portada:", len(noticias))


# ---------- EMBEDDINGS ----------

titulos = [n["titulo"] for n in noticias]
embeddings = modelo.encode(titulos, batch_size=32) if titulos else np.array([])


# ---------- CLUSTERING ----------

grupos = []

for i, emb in enumerate(embeddings):

    mejor_grupo = None
    mejor_score = 0

    for grupo in grupos:
        centroide = np.mean(embeddings[grupo], axis=0)
        score = cosine_similarity([emb], [centroide])[0][0]

        if score > mejor_score:
            mejor_score = score
            mejor_grupo = grupo

    if mejor_score > UMBRAL_CLUSTER:
        mejor_grupo.append(i)
    else:
        grupos.append([i])

if not grupos:
    grupos = [[i] for i in range(len(noticias))]

grupos.sort(key=len, reverse=True)


# ---------- TITULAR IA ----------

def titular_prisma(indices):

    palabras = []
    for i in indices:
        palabras += limpiar(noticias[i]["titulo"])

    comunes = [p for p, _ in Counter(palabras).most_common(5)]
    blacklist = {"gobierno","espa√±a","hoy","√∫ltima","√∫ltimas"}

    comunes = [p for p in comunes if p not in blacklist][:3]

    tema = ", ".join(comunes)

    prefijos = [
        "üß≠ Claves informativas:",
        "üìä En el foco:",
        "üì∞ Lo que domina hoy:",
        "üî• Tema principal:"
    ]

    return f"{random.choice(prefijos)} {tema.capitalize()}"


def resumen_prisma(indices):

    palabras = []
    for i in indices:
        palabras += limpiar(noticias[i]["titulo"])

    comunes = [p for p, _ in Counter(palabras).most_common(6)]

    blacklist = {
        "gobierno","espa√±a","√∫ltima","hoy",
        "seg√∫n","dice","a√±os","parte"
    }

    comunes = [p for p in comunes if p not in blacklist][:2]

    if not comunes:
        return ""

    tema = " y ".join(comunes)

    frases = [
        f"Panorama informativo centrado en <b>{tema}</b>.",
        f"Las noticias destacan especialmente <b>{tema}</b>.",
        f"El foco medi√°tico gira en torno a <b>{tema}</b>."
    ]

    return f"""
<p class="resumen">
üß† <b>Resumen IA:</b> {random.choice(frases)}
</p>
"""


# ---------- FEEDS INTERNACIONALES ‚Üí ESPA√ëA ----------

KEYWORDS_ESPANA = [
    "espa√±a","spain","espagne","spanien","spagna",
    "spanish","espa√±ol","madrid","barcelona",
    "catalonia","andalusia","valencia","canary",
    "spaniard","spaniards"
]

noticias_espana = []

for medio, url in feeds_internacionales.items():
    feed = feedparser.parse(url)

    if feed.bozo:
        continue

    for entry in feed.entries[:10]:
        if "title" in entry:
            titulo = limpiar_html(entry.title)

            if any(k in titulo.lower() for k in KEYWORDS_ESPANA):
                noticias_espana.append({
                    "medio": medio,
                    "titulo": titulo,
                    "link": entry.link
                })


# üëâ ordenar por relevancia simple
noticias_espana.sort(key=lambda x: len(x["titulo"]), reverse=True)


# ---------- FECHAS ----------

fecha = datetime.now()
fecha_legible = fecha.strftime("%d/%m %H:%M")
fecha_iso = fecha.isoformat()
cachebuster = fecha.timestamp()
medios_unicos = len(set(n["medio"] for n in noticias))


# ---------- HTML PORTADA ----------

html = f"""<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">
<title>Prisma | Comparador IA noticias</title>
<link rel="stylesheet" href="prisma.css?v={cachebuster}">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>

<header class="header">
<div class="logo">
<img src="Logo.PNG" class="logo-img">
<a href="index.html" class="logo-link">PRISMA</a>
</div>

<p class="tagline">M√°s contexto ¬∑ menos ruido</p>

<div class="stats">
üì∞ {medios_unicos} medios analizados ¬∑
<time datetime="{fecha_iso}">Actualizado: {fecha_legible}</time>
</div>

<nav class="nav">
<a href="index.html">Inicio</a>
<a href="sobre.html">Sobre Prisma</a>
<a href="espana.html">Espa√±a en el mundo</a>
<a href="mailto:ovalero@gmail.com">Contacto</a>
</nav>
</header>

<div class="container">
"""

for i, grupo in enumerate(grupos, 1):

    clase = "card portada" if i == 1 else "card"

    html += f"""
<div class="{clase}">
<h2>{titular_prisma(grupo)}</h2>
{resumen_prisma(grupo)}
"""

    for idx in grupo[:6]:
        n = noticias[idx]
        html += f"""
<p><strong>{n['medio']}:</strong>
<a href="{n['link']}" target="_blank" rel="noopener noreferrer">
{n['titulo']}
</a></p>
"""

    html += "</div>"

html += "</div></body></html>"

with open("index.html","w",encoding="utf-8") as f:
    f.write(html)


# ---------- HTML ESPA√ëA EN EL MUNDO ----------

html_espana = f"""
<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">
<title>Espa√±a en el mundo | Prisma</title>
<link rel="stylesheet" href="prisma.css?v={cachebuster}">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>

<header class="header">
<div class="logo">
<img src="Logo.PNG" class="logo-img">
<a href="index.html" class="logo-link">PRISMA</a>
</div>

<nav class="nav">
<a href="index.html">Inicio</a>
<a href="sobre.html">Sobre Prisma</a>
<a href="espana.html">Espa√±a en el mundo</a>
<a href="mailto:ovalero@gmail.com">Contacto</a>
</nav>
</header>

<div class="container">
<div class="card portada">
<h2>üåç Espa√±a en el mundo</h2>
"""

for n in noticias_espana[:40]:
    html_espana += f"""
<p><strong>{n['medio']}:</strong>
<a href="{n['link']}" target="_blank" rel="noopener noreferrer">
{n['titulo']}
</a></p>
"""

html_espana += "</div></div></body></html>"

with open("espana.html","w",encoding="utf-8") as f:
    f.write(html_espana)


print("PRISMA OPTIMIZADO GENERADO üöÄ")
