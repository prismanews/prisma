import feedparser
import re
import html
import random
from datetime import datetime
from collections import Counter
import numpy as np

from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity


# ---------- CONFIG PRO ----------

UMBRAL_CLUSTER = 0.63
UMBRAL_DUPLICADO = 0.87
MAX_NOTICIAS_FEED = 8

modelo = SentenceTransformer("all-MiniLM-L6-v2")


# ---------- REFERENCIAS NLP SESGO (MEJORADAS PRO) ----------

referencias_politicas = {
    "progresista": modelo.encode([
        # espa침ol
        "derechos sociales igualdad feminismo justicia social diversidad pol칤ticas p칰blicas bienestar",
        "progresismo cambio clim치tico pol칤ticas sociales regulaci칩n inclusi칩n servicios p칰blicos",

        # ingl칠s
        "social justice equality progressive politics climate action diversity welfare public services",
        "left wing policies regulation social rights inclusion government intervention",

        # internacional neutro
        "environmental protection social equality human rights public healthcare welfare state"
    ]),

    "conservador": modelo.encode([
        # espa침ol
        "seguridad fronteras defensa tradici칩n econom칤a mercado estabilidad control migratorio",
        "valores tradicionales seguridad nacional impuestos bajos orden liberalismo econ칩mico",

        # ingl칠s
        "border security national defense free market traditional values low taxes immigration control",
        "conservative policies economic freedom national identity law and order",

        # internacional neutro
        "fiscal responsibility strong military traditional culture business friendly policies"
    ])
}

# ---------- FEEDS ----------
feeds = {
    "El Pa칤s": "https://feeds.elpais.com/mrss-s/pages/ep/site/elpais.com/portada",
    "El Mundo": "https://e00-elmundo.uecdn.es/elmundo/rss/portada.xml",
    "ABC": "https://www.abc.es/rss/feeds/abcPortada.xml",
    "La Vanguardia": "https://www.lavanguardia.com/rss/home.xml",
    "20 Minutos": "https://www.20minutos.es/rss/",
    "eldiario.es": "https://www.eldiario.es/rss/",
    "Europa Press": "https://www.europapress.es/rss/rss.aspx",
    "El Espa침ol": "https://www.elespanol.com/rss/",
    "RTVE": "https://www.rtve.es/rss/",
    "BBC Mundo": "https://feeds.bbci.co.uk/mundo/rss.xml",
    "France24 Espa침ol": "https://www.france24.com/es/rss",
    "DW Espa침ol": "https://rss.dw.com/xml/rss-es-all",
    "El Confidencial": "https://www.elconfidencial.com/rss/",
    "P칰blico": "https://www.publico.es/rss/",
    "HuffPost": "https://www.huffingtonpost.es/feeds/index.xml",
    "CNN Espa침ol": "https://cnnespanol.cnn.com/feed/",
    "NYTimes World": "https://rss.nytimes.com/services/xml/rss/nyt/World.xml",
    "La Voz de Galicia": "https://www.lavozdegalicia.es/rss/portada.xml",
    "El Correo": "https://www.elcorreo.com/rss/portada.xml",
    "Diario Sur": "https://www.diariosur.es/rss/portada.xml",
    "Levante": "https://www.levante-emv.com/rss/portada.xml",
    "Heraldo": "https://www.heraldo.es/rss/portada/",
    "Xataka": "https://www.xataka.com/feedburner.xml",
    "Genbeta": "https://www.genbeta.com/feedburner.xml",
    "Trendencias": "https://www.trendencias.com/feedburner.xml",
    "Verne": "https://feeds.elpais.com/mrss-s/pages/ep/site/verne.elpais.com/portada",
    "Yorokobu": "https://www.yorokobu.es/feed/",
    "The Guardian": "https://www.theguardian.com/world/rss",
    "Reuters": "https://www.reutersagency.com/feed/?best-topics=general-news",
    "Al Jazeera": "https://www.aljazeera.com/xml/rss/all.xml",
    "El Peri칩dico": "https://www.elperiodico.com/es/rss/rss_portada.xml",
    "Diario Vasco": "https://www.diariovasco.com/rss/portada.xml",
    "Informaci칩n Alicante": "https://www.informacion.es/rss/portada.xml",
    "Hipertextual": "https://hipertextual.com/feed",
    "Microsiervos": "https://www.microsiervos.com/index.xml",
    "Applesfera": "https://www.applesfera.com/feedburner.xml",
    "Expansi칩n": "https://e00-expansion.uecdn.es/rss/portada.xml",
    "Cinco D칤as": "https://cincodias.elpais.com/seccion/rss/portada/",
    "Nature News": "https://www.nature.com/nature.rss",
    "Scientific American": "https://rss.sciam.com/ScientificAmerican-Global",
    "Infolibre": "https://www.infolibre.es/rss",
    "El Salto": "https://www.elsaltodiario.com/rss",
    "CTXT": "https://ctxt.es/es/feed/",
    "Jacobin": "https://jacobin.com/feed",
    "Politico EU": "https://www.politico.eu/feed/",
    "OpenDemocracy": "https://www.opendemocracy.net/en/rss.xml"
}

feeds_internacionales = {

    # 游섫릖 Ingl칠s
    "BBC World": "https://feeds.bbci.co.uk/news/world/rss.xml",
    "CNN World": "http://rss.cnn.com/rss/edition_world.rss",
    "Reuters": "https://www.reutersagency.com/feed/?best-topics=world",
    "NYTimes": "https://rss.nytimes.com/services/xml/rss/nyt/World.xml",
    "Guardian": "https://www.theguardian.com/world/rss",
    "Bloomberg": "https://feeds.bloomberg.com/markets/news.rss",
    "Financial Times": "https://www.ft.com/world?format=rss",

    # 游游 Franc칠s
    "Le Monde": "https://www.lemonde.fr/rss/une.xml",
    "France24 FR": "https://www.france24.com/fr/rss",
    "Le Figaro": "https://www.lefigaro.fr/rss/figaro_actualites.xml",

    # 游뾇릖 Alem치n
    "Der Spiegel": "https://www.spiegel.de/international/index.rss",
    "Die Welt": "https://www.welt.de/feeds/latest.rss",

    # 游쉻릖 Italiano
    "Corriere": "https://xml2.corriereobjects.it/rss/homepage.xml",
    "La Repubblica": "https://www.repubblica.it/rss/homepage/rss2.0.xml",

    # 游왫릖 Portugu칠s
    "Publico PT": "https://www.publico.pt/rss",
    "Folha Brasil": "https://feeds.folha.uol.com.br/emcimadahora/rss091.xml",

    # 游쀯릖 Europa general
    "Politico EU": "https://www.politico.eu/feed/",
    "Euronews": "https://www.euronews.com/rss?level=theme&name=news",

    # 游깶 Asia
    "SCMP Hong Kong": "https://www.scmp.com/rss/91/feed",
    "Japan Times": "https://www.japantimes.co.jp/feed/",
    "China Daily": "http://www.chinadaily.com.cn/rss/world_rss.xml",

    # 游깵 Am칠rica Latina internacional
    "Clarin": "https://www.clarin.com/rss/lo-ultimo/",
    "El Tiempo CO": "https://www.eltiempo.com/rss/colombia.xml",
    "Granma": "http://www.granma.cu/feed",
    "Cubadebate": "http://www.cubadebate.cu/feed/",
    "Prensa Latina": "https://www.prensa-latina.cu/feed/"
}
KEYWORDS_ESPANA = [
    # pa칤s b치sico
    "espa침a","espana","spain","espagne","spanien","spagna",
    "spanish","espa침ol","spaniard","spaniards",

    # ciudades clave internacionales
    "madrid","barcelona","valencia","seville","sevilla",
    "bilbao","zaragoza","malaga","granada","ibiza",

    # regiones y territorios
    "catalonia","catalu침a","basque","galicia",
    "andalusia","balearic","canary islands","canarias",

    # pol칤tica / gobierno
    "spanish government","gobierno espa침ol",
    "pedro sanchez","s치nchez","feijoo","vox spain",

    # econom칤a / sociedad
    "spanish economy","econom칤a espa침ola",
    "housing spain","tourism spain",
    "spanish tourism",

    # cultura / deporte (muy internacional)
    "la liga","real madrid","fc barcelona",
    "spanish football",

    # UE / geopol칤tica
    "spain eu","spanish presidency eu",
    "nato spain"
]
# ---------- LIMPIEZA ----------

stopwords = {
    # art칤culos / b치sicos espa침ol
    "el","la","los","las","un","una","unos","unas",
    "de","del","al","a","en","por","para","con","sin",
    "sobre","entre","hasta","desde",

    # conjunciones / conectores
    "y","o","e","ni","que","como","pero","aunque",
    "porque","ya","tambi칠n","solo",

    # posesivos / pronombres
    "su","sus","se","lo","le","les","esto","esta",
    "estos","estas","ese","esa","esos","esas",

    # tiempo t칤pico noticias
    "hoy","ayer","ma침ana","tras","antes","despu칠s",
    "칰ltima","칰ltimas","칰ltimo","칰ltimos",

    # palabras period칤sticas vac칤as
    "dice","seg칰n","afirma","asegura","explica",
    "parte","caso","forma","vez","a침os",

    # ingl칠s frecuente en feeds
    "the","a","an","of","to","in","on","for","with",
    "and","or","but","from","by","about","as",
    "after","before","over","under",

    # prensa internacional t칤pica
    "says","said","report","reports","new","latest",
    "update","breaking","news"
}


def limpiar_html(texto):
    texto = html.unescape(texto)
    texto = re.sub(r'<.*?>', '', texto)
    return re.sub(r'\s+', ' ', texto).strip()


def limpiar(texto):
    texto = texto.lower()
    texto = re.sub(r'[^\w\s]', '', texto)
    palabras = texto.split()
    return [p for p in palabras if p not in stopwords and len(p) > 3]


# ---------- RECOGER NOTICIAS ----------

noticias = []

for medio, url in feeds.items():
    try:
        feed = feedparser.parse(url, request_headers={'User-Agent': 'Mozilla/5.0'})
        for entry in feed.entries[:MAX_NOTICIAS_FEED]:
            if "title" in entry and "link" in entry:
                noticias.append({
                    "medio": medio,
                    "titulo": limpiar_html(entry.title),
                    "link": entry.link.strip()
                })
    except Exception as e:
        print(f"Error feed {medio}: {e}")

print("Noticias recogidas:", len(noticias))

# ---------- INTERNACIONAL ESPA칌A (solo nueva p치gina) ----------

noticias_espana = []

for medio, url in feeds_internacionales.items():
    try:
        feed = feedparser.parse(url, request_headers={'User-Agent': 'Mozilla/5.0'})
        if feed.bozo:
            continue

        for entry in feed.entries[:6]:

            # evita feeds rotos o incompletos
            if "title" not in entry or "link" not in entry:
                continue

            titulo = limpiar_html(entry.title)

            if any(k in titulo.lower() for k in KEYWORDS_ESPANA):
                noticias_espana.append({
                    "medio": medio,
                    "titulo": titulo,
                    "link": entry.link
                })

    except Exception:
        pass

# quitar duplicados internacionales
noticias_espana = list({n["link"]: n for n in noticias_espana}.values())
noticias_espana.sort(key=lambda x: len(x["titulo"]), reverse=True)

# ---------- EMBEDDINGS ----------

titulos = [n["titulo"] for n in noticias]

if not titulos:
    print("丘멆잺 No hay titulares.")
    embeddings = np.array([])
else:
    embeddings = modelo.encode(titulos, batch_size=32)


# ---------- DEDUPLICADO ----------

filtradas = []
emb_filtrados = []

for i, emb in enumerate(embeddings):

    if not emb_filtrados:
        filtradas.append(noticias[i])
        emb_filtrados.append(emb)
        continue

    similitudes = cosine_similarity([emb], emb_filtrados)[0]

    if max(similitudes) < UMBRAL_DUPLICADO:
        filtradas.append(noticias[i])
        emb_filtrados.append(emb)

noticias = filtradas
embeddings = np.array(emb_filtrados)


# ---------- CLUSTERING PRO (NO P츼GINA VAC칈A) ----------

grupos = []

for i, emb in enumerate(embeddings):

    mejor_grupo = None
    mejor_score = 0

    for grupo in grupos:
        centroide = np.mean(embeddings[grupo], axis=0)
        score = cosine_similarity([emb], [centroide])[0][0]

        if score > mejor_score:
            mejor_score = score
            mejor_grupo = grupo

    if mejor_score > UMBRAL_CLUSTER:
        mejor_grupo.append(i)
    else:
        grupos.append([i])


# 游녤 FIX PROFESIONAL:
# evita p치gina vac칤a si no hay clusters claros
if not grupos or all(len(g) < 2 for g in grupos):
    grupos = [[i] for i in range(len(noticias))]
else:
    grupos = [g for g in grupos if len(g) >= 2]

grupos.sort(key=len, reverse=True)


# ---------- SESGO NLP MEJORADO ----------

def sesgo_politico(indices):

    textos = [noticias[i]["titulo"] for i in indices]
    emb = modelo.encode(textos, batch_size=16)

    centroide = np.mean(emb, axis=0).reshape(1, -1)

    prog = cosine_similarity(
        centroide,
        referencias_politicas["progresista"]
    ).mean()

    cons = cosine_similarity(
        centroide,
        referencias_politicas["conservador"]
    ).mean()

    # ajuste fino NLP
    if abs(prog - cons) < 0.015:
        texto = "Cobertura bastante equilibrada"
    elif prog > cons:
        texto = "Enfoque algo progresista"
    else:
        texto = "Enfoque algo conservador"

    return f"""
<div class="sesgo">
丘뒲잺 <b>Sesgo IA:</b> {texto}
</div>
"""


# ---------- TITULAR IA ----------

def titular_prisma(indices):

    palabras = []
    for i in indices:
        palabras += limpiar(noticias[i]["titulo"])

    comunes = [p for p, _ in Counter(palabras).most_common(5)]

    # elimina palabras muy gen칠ricas
    blacklist = {"gobierno", "espa침a", "hoy", "칰ltima", "칰ltimas"}
    comunes = [p for p in comunes if p not in blacklist][:3]

    tema = ", ".join(comunes)

    prefijos = [
        "游빐 Claves informativas:",
        "游늵 En el foco:",
        "游닗 Lo que domina hoy:",
        "游댠 Tema principal:"
    ]

    return f"{random.choice(prefijos)} {tema.capitalize()}"

def resumen_prisma(indices):

    palabras = []
    for i in indices:
        palabras += limpiar(noticias[i]["titulo"])

    comunes = [p for p, _ in Counter(palabras).most_common(6)]

    blacklist = {
        "gobierno","espa침a","칰ltima","hoy","tras",
        "seg칰n","dice","a침os","parte"
    }

    comunes = [p for p in comunes if p not in blacklist][:2]

    if not comunes:
        return ""

    tema = " y ".join(comunes)

    return f"""
<p class="resumen">
游 <b>Resumen IA:</b>
La actualidad informativa se centra en <b>{tema}</b>.
</p>
"""
    
fecha = datetime.now()
fecha_legible = fecha.strftime("%d/%m %H:%M")
fecha_iso = fecha.isoformat()
cachebuster = fecha.timestamp()
medios_unicos = len(set(n["medio"] for n in noticias))

# ---------- HTML ----------

html = f"""
<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">

<!-- Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9WZC3GQSN8"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){{dataLayer.push(arguments);}}
gtag('js', new Date());
gtag('config', 'G-9WZC3GQSN8');
</script>

<title>Prisma | Comparador IA de noticias</title>

<meta name="description"
content="Comparador inteligente de noticias. Analiza m칰ltiples medios para ofrecer contexto y reducir ruido informativo.">

<meta name="robots" content="index, follow, max-image-preview:large">
<meta name="googlebot" content="index, follow">
<link rel="canonical" href="https://prismanews.github.io/prisma/">

<!-- Open Graph -->
<meta property="og:title" content="Prisma noticias IA">
<meta property="og:description" content="Comparador inteligente de noticias con IA">
<meta property="og:image" content="Logo.PNG">
<meta property="og:type" content="website">
<meta property="og:url" content="https://prismanews.github.io/prisma/">
<meta http-equiv="content-language" content="es">

<!-- SEO extra -->
<meta name="theme-color" content="#ffffff">
<meta name="author" content="Prisma News">

<link rel="stylesheet" href="prisma.css?v={cachebuster}">
<meta name="viewport" content="width=device-width, initial-scale=1">

</head>
<body>

<header class="header">
<div class="logo">
<img src="Logo.PNG" class="logo-img">
<a href="index.html" class="logo-link">PRISMA</a>
</div>

<p class="tagline">M치s contexto 췅 menos ruido</p>

<p class="gancho">
Comparador inteligente de medios 췅 Detecta sesgos 췅 Entiende la actualidad mejor
</p>

<p style="font-size:14px;color:#666;margin-top:6px;">
An치lisis autom치tico de titulares de m치s de 25 medios para detectar tendencias informativas y comparar enfoques editoriales.
</p>

<div class="stats">
游닗 {medios_unicos} medios analizados 췅
<time datetime="{fecha_iso}">Actualizado: {fecha_legible}</time>
</div>

<nav class="nav">
<a href="index.html">Inicio</a>
<a href="sobre.html">Sobre Prisma</a>
<a href="espana.html">Espa침a en el mundo</a>
<a href="mailto:ovalero@gmail.com?subject=Contacto%20Prisma">
Contacto
</a>
</nav>
</header>

<div class="container">
"""

for i, grupo in enumerate(grupos, 1):

    clase = "card"
    if i == 1:
        clase = "card portada"
    html += f"""
<div class="{clase}">

<h2>{titular_prisma(grupo)}</h2>
{resumen_prisma(grupo)}
{sesgo_politico(grupo)} 
"""

    for idx in grupo[:6]:
        n = noticias[idx]
        html += f"""
<p>
<strong>{n['medio']}:</strong>
<a href="{n['link']}" target="_blank" rel="noopener noreferrer">{n['titulo']}</a>
</p>
"""
  
    html += "</div>"


# 游녤 Truco tr치fico joven (SEO + UX)
html += """
<footer style="text-align:center;opacity:.7;margin:40px 0;font-size:.9em">
Comparador autom치tico de noticias con IA 췅 Actualizaci칩n continua
</footer>
"""

html += "</div></body></html>"

with open("index.html", "w", encoding="utf-8") as f:
    f.write(html)


# ---------- SITEMAP ----------

sitemap = """<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
<url><loc>https://prismanews.github.io/prisma/</loc></url>
<url><loc>https://prismanews.github.io/prisma/espana.html</loc></url>
</urlset>
"""

with open("sitemap.xml", "w", encoding="utf-8") as f:
    f.write(sitemap)

# ---------- HTML ESPA칌A EN EL MUNDO ----------

html_espana = f"""
<!DOCTYPE html>
<html lang="es">
<head>
<meta charset="UTF-8">
<meta name="robots" content="index, follow">
<meta name="googlebot" content="index, follow">
<title>Espa침a en el mundo | Prisma</title>
<link rel="stylesheet" href="prisma.css?v={cachebuster}">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>

<header class="header">
<div class="logo">
<img src="Logo.PNG" class="logo-img">
<a href="index.html" class="logo-link">PRISMA</a>
</div>

<nav class="nav">
<a href="index.html">Inicio</a>
<a href="sobre.html">Sobre Prisma</a>
<a href="espana.html">Espa침a en el mundo</a>
<a href="mailto:ovalero@gmail.com?subject=Contacto%20Prisma">
Contacto
</a>
</nav>
</header>

<div class="container">
<div class="card portada">
<h2>游깴 Espa침a en el mundo</h2>
<p>Visi칩n de la prensa internacional sobre Espa침a.</p>
"""

for n in noticias_espana[:40]:
    html_espana += f"""
<p>
<strong>{n['medio']}:</strong>
<a href="{n['link']}" target="_blank" rel="noopener noreferrer">
{n['titulo']}
</a>
</p>
"""

html_espana += "</div></div></body></html>"

with open("espana.html", "w", encoding="utf-8") as f:
    f.write(html_espana)

# ---------- ROBOTS ----------

robots = """User-agent: *
Allow: /

Sitemap: https://prismanews.github.io/prisma/sitemap.xml
"""

with open("robots.txt", "w", encoding="utf-8") as f:
    f.write(robots)


print("PRISMA NLP PRO generado 游")
